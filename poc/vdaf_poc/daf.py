"""Definition of DAFs."""

from abc import ABCMeta, abstractmethod
from typing import Generic, TypeVar

from vdaf_poc.common import gen_rand

Measurement = TypeVar("Measurement")
AggParam = TypeVar("AggParam")
PublicShare = TypeVar("PublicShare")
InputShare = TypeVar("InputShare")
OutShare = TypeVar("OutShare")
AggShare = TypeVar("AggShare")
AggResult = TypeVar("AggResult")


class Daf(
        Generic[
            Measurement, AggParam, PublicShare, InputShare, OutShare, AggShare,
            AggResult
        ],
        metaclass=ABCMeta):
    """
    A Distributed Aggregation Function (DAF).

    Generic type parameters:
    Measurement -- the measurement type
    AggParam -- the aggregation parameter type
    PublicShare -- the public share type
    InputShare -- the input share type
    OutShare -- the output share type
    AggShare -- the aggregate share type
    AggResult -- the aggregate result type

    Attributes:
    ID -- algorithm identifier, a 32-bit integer
    SHARES -- the number of Aggregators
    NONCE_SIZE -- length of the nonce
    RAND_SIZE -- number of random bytes consumed by `shard()`
    """

    # Algorithm identifier for this DAF, a 32-bit integer.
    ID: int

    # The number of Aggregators.
    SHARES: int

    # Length of the nonce.
    NONCE_SIZE: int

    # Number of random bytes consumed by `shard()`.
    RAND_SIZE: int

    @abstractmethod
    def shard(
            self,
            ctx: bytes,
            measurement: Measurement,
            nonce: bytes,
            rand: bytes) -> tuple[PublicShare, list[InputShare]]:
        """
        Shard a measurement into a public share and a sequence of input
        shares, one for each Aggregator. This method is run by the Client.

        Pre-conditions:

            - `len(nonce) == Daf.NONCE_SIZE`
            - `len(rand) == Daf.RAND_SIZE`
        """
        pass

    @abstractmethod
    def is_valid(
            self,
            agg_param: AggParam,
            previous_agg_params: list[AggParam]) -> bool:
        """
        Check if `agg_param` is valid for use with an input share that has
        previously been used with all `previous_agg_params`.
        """
        pass

    @abstractmethod
    def prep(
            self,
            ctx: bytes,
            agg_id: int,
            agg_param: AggParam,
            nonce: bytes,
            public_share: PublicShare,
            input_share: InputShare) -> OutShare:
        """
        Prepare an input share for aggregation. This algorithm takes in the
        public share and one of the input shares generated by the Client. It
        also takes in the application context, the Aggregator's ID (a unique
        integer in range `[0, SHARES)` corresponding to the index of
        `input_share` in the Client's output), and an aggregation parameter and
        returns the corresponding output share.

        Pre-conditions:

            - `agg_id` in `[0, daf.SHARES)`
            - `len(nonce) == daf.NONCE_SIZE`
        """
        pass

    @abstractmethod
    def agg_init(self,
                 agg_param: AggParam) -> AggShare:
        """
        Return an empty aggregate share.
        """
        pass

    @abstractmethod
    def agg_update(self,
                   agg_param: AggParam,
                   agg_share: AggShare,
                   out_share: OutShare) -> AggShare:
        """
        Accumulate an output share into an aggregate share and return the
        updated aggregate share.
        """
        pass

    @abstractmethod
    def merge(self,
              agg_param: AggParam,
              agg_shares: list[AggShare]) -> AggShare:
        """
        Merge a sequence of aggregate shares into a single aggregate share.
        """
        pass

    @abstractmethod
    def unshard(
            self,
            agg_param: AggParam,
            agg_shares: list[AggShare],
            num_measurements: int) -> AggResult:
        """
        Unshard the aggregate shares (encoded as byte strings) and compute the
        aggregate result. This is called by the Collector.
        """
        pass


# NOTE: This function is excerpted in the document, as the figure
# {{run-daf}}. Its width should be limited to 69 columns to avoid
# warnings from xml2rfc.
# ===================================================================
def run_daf(
        daf: Daf[
            Measurement,
            AggParam,
            PublicShare,
            InputShare,
            OutShare,
            AggShare,
            AggResult,
        ],
        ctx: bytes,
        agg_param: AggParam,
        measurements: list[Measurement],
        nonces: list[bytes]) -> AggResult:
    """
    Run a DAF on a list of measurements.

    Pre-conditions:

        - `type(agg_param) == daf.AggParam`
        - `type(measurement) == daf.Measurement` for each
          `measurement` in `measurements`
        - `len(nonce) == daf.NONCE_SIZE` for each `nonce` in `nonces`
        - `len(nonces) == len(measurements)`
    """
    if any(len(nonce) != daf.NONCE_SIZE for nonce in nonces):
        raise ValueError("incorrect nonce size")
    if len(nonces) != len(measurements):
        raise ValueError(
            "measurements and nonces lists have different lengths"
        )

    agg_shares: list[AggShare]
    agg_shares = [daf.agg_init(agg_param)
                  for _ in range(daf.SHARES)]
    for (measurement, nonce) in zip(measurements, nonces):
        # Each Client shards its measurement into input shares and
        # distributes them among the Aggregators.
        rand = gen_rand(daf.RAND_SIZE)
        (public_share, input_shares) = \
            daf.shard(ctx, measurement, nonce, rand)

        # Each Aggregator computes its output share from its input
        # share and aggregates it.
        for j in range(daf.SHARES):
            out_share = daf.prep(ctx, j, agg_param, nonce,
                                 public_share, input_shares[j])
            agg_shares[j] = daf.agg_update(agg_param,
                                           agg_shares[j],
                                           out_share)

    # Collector unshards the aggregate result.
    num_measurements = len(measurements)
    agg_result = daf.unshard(agg_param, agg_shares,
                             num_measurements)
    return agg_result
