"""Definition of DAFs."""

from abc import ABCMeta, abstractmethod
from typing import Generic, TypeVar, override

from vdaf_poc.common import gen_rand

Measurement = TypeVar("Measurement")
AggParam = TypeVar("AggParam")
PublicShare = TypeVar("PublicShare")
InputShare = TypeVar("InputShare")
OutShare = TypeVar("OutShare")
AggShare = TypeVar("AggShare")
AggResult = TypeVar("AggResult")


class DistributedAggregation(
        Generic[
            Measurement, AggParam, PublicShare, InputShare, OutShare, AggShare,
            AggResult
        ],
        metaclass=ABCMeta):
    """
    Abstract base class containing methods common to DAFs and VDAFs.
    """

    @abstractmethod
    def shard(self,
              ctx: bytes,
              measurement: Measurement,
              nonce: bytes,
              rand: bytes,
              ) -> tuple[PublicShare, list[InputShare]]:
        pass

    @abstractmethod
    def is_valid(self,
                 agg_param: AggParam,
                 previous_agg_params: list[AggParam]) -> bool:
        pass

    @abstractmethod
    def agg_init(self, agg_param: AggParam) -> AggShare:
        pass

    @abstractmethod
    def agg_update(self,
                   agg_param: AggParam,
                   agg_share: AggShare,
                   out_share: OutShare) -> AggShare:
        pass

    @abstractmethod
    def merge(self,
              agg_param: AggParam,
              agg_shares: list[AggShare]) -> AggShare:
        pass

    @abstractmethod
    def unshard(self,
                agg_param: AggParam,
                agg_shares: list[AggShare],
                num_measurements: int) -> AggResult:
        pass


class Daf(
        Generic[
            Measurement, AggParam, PublicShare, InputShare, OutShare, AggShare,
            AggResult
        ],
        DistributedAggregation[
            Measurement, AggParam, PublicShare, InputShare, OutShare, AggShare,
            AggResult
        ]):
    """
    A Distributed Aggregation Function (DAF).

    Generic type parameters:
    Measurement -- the measurement type
    AggParam -- the aggregation parameter type
    PublicShare -- the public share type
    InputShare -- the input share type
    OutShare -- the output share type
    AggShare -- the aggregate share type
    AggResult -- the aggregate result type

    Attributes:
    ID -- algorithm identifier, a 32-bit integer
    SHARES -- the number of Aggregators
    NONCE_SIZE -- length of the nonce
    RAND_SIZE -- number of random bytes consumed by `shard()`
    """

    # Algorithm identifier for this DAF, a 32-bit integer.
    ID: int

    # The number of Aggregators.
    SHARES: int

    # Length of the nonce.
    NONCE_SIZE: int

    # Number of random bytes consumed by `shard()`.
    RAND_SIZE: int

    @override
    @abstractmethod
    def shard(
            self,
            ctx: bytes,
            measurement: Measurement,
            nonce: bytes,
            rand: bytes) -> tuple[PublicShare, list[InputShare]]:
        """
        Shard a measurement into a public share and a sequence of input
        shares, one for each Aggregator. This method is run by the Client.

        Pre-conditions:

            - `len(nonce) == Daf.NONCE_SIZE`
            - `len(rand) == Daf.RAND_SIZE`
        """
        pass

    @override
    @abstractmethod
    def is_valid(
            self,
            agg_param: AggParam,
            previous_agg_params: list[AggParam]) -> bool:
        """
        Check if `agg_param` is valid for use with an input share that has
        previously been used with all `previous_agg_params`.
        """
        pass

    @abstractmethod
    def prep(
            self,
            ctx: bytes,
            agg_id: int,
            agg_param: AggParam,
            nonce: bytes,
            public_share: PublicShare,
            input_share: InputShare) -> OutShare:
        """
        Prepare an input share for aggregation. This algorithm takes in the
        public share and one of the input shares generated by the Client. It
        also takes in the application context, the Aggregator's ID (a unique
        integer in the range `[0, SHARES)` corresponding to the index of
        `input_share` in the Client's output), and an aggregation parameter and
        returns the corresponding output share.

        Pre-conditions:

            - `agg_id` in the range `[0, daf.SHARES)`
            - `len(nonce) == daf.NONCE_SIZE`
        """
        pass

    @override
    @abstractmethod
    def agg_init(self,
                 agg_param: AggParam) -> AggShare:
        """
        Return an empty aggregate share.
        """
        pass

    @override
    @abstractmethod
    def agg_update(self,
                   agg_param: AggParam,
                   agg_share: AggShare,
                   out_share: OutShare) -> AggShare:
        """
        Accumulate an output share into an aggregate share and return the
        updated aggregate share.
        """
        pass

    @override
    @abstractmethod
    def merge(self,
              agg_param: AggParam,
              agg_shares: list[AggShare]) -> AggShare:
        """
        Merge a sequence of aggregate shares into a single aggregate share.
        """
        pass

    @override
    @abstractmethod
    def unshard(
            self,
            agg_param: AggParam,
            agg_shares: list[AggShare],
            num_measurements: int) -> AggResult:
        """
        Unshard the aggregate shares (encoded as byte strings) and compute the
        aggregate result. This is called by the Collector.
        """
        pass


# NOTE: This function is excerpted in the document, as the figure
# {{run-daf}}. Its width should be limited to 69 columns to avoid
# warnings from xml2rfc.
# ===================================================================
def run_daf(
        daf: Daf[
            Measurement,
            AggParam,
            PublicShare,
            InputShare,
            OutShare,
            AggShare,
            AggResult,
        ],
        ctx: bytes,
        agg_param: AggParam,
        measurements: list[Measurement]) -> AggResult:
    agg_shares: list[AggShare]
    agg_shares = [daf.agg_init(agg_param)
                  for _ in range(daf.SHARES)]
    for measurement in measurements:
        # Sharding
        nonce = gen_rand(daf.NONCE_SIZE)
        rand = gen_rand(daf.RAND_SIZE)
        (public_share, input_shares) = \
            daf.shard(ctx, measurement, nonce, rand)

        # Preparation, aggregation
        for j in range(daf.SHARES):
            out_share = daf.prep(ctx, j, agg_param, nonce,
                                 public_share, input_shares[j])
            agg_shares[j] = daf.agg_update(agg_param,
                                           agg_shares[j],
                                           out_share)

    # Unsharding
    num_measurements = len(measurements)
    agg_result = daf.unshard(agg_param, agg_shares,
                             num_measurements)
    return agg_result
