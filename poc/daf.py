"""Definition of DAFs."""

from __future__ import annotations

from common import Bool, Unsigned, gen_rand


class Daf:
    """A DAF"""

    # Algorithm identifier for this DAF, a 32-bit integer.
    ID: Unsigned = None

    # The number of Aggregators.
    SHARES: Unsigned = None

    # Length of the nonce.
    NONCE_SIZE = None

    # Number of random bytes consumed by `shard()`.
    RAND_SIZE = None

    # The measurement type.
    Measurement = None

    # The aggregation parameter type.
    AggParam = None

    # The public share type.
    PublicShare = None

    # The input share type.
    InputShare = None

    # The output share type.
    OutShare = None

    # The aggregate share type.
    AggShare = None

    # The aggregate result type.
    AggResult = None

    @classmethod
    def shard(Daf,
              measurement: Measurement,
              nonce: bytes["Daf.NONCE_SIZE"],
              rand: bytes["Daf.RAND_SIZE"],
              ) -> tuple[PublicShare, list[InputShare]]:
        """
        Shard a measurement into a public share and a sequence of input
        shares, one for each Aggregator. This method is run by the Client.
        """
        raise NotImplementedError()

    @classmethod
    def is_valid(Daf, agg_param: AggParam,
                 previous_agg_params: set[AggParam]) -> Bool:
        """
        Check if `agg_param` is valid for use with an input share that has
        previously been used with all `previous_agg_params`.
        """
        raise NotImplementedError()

    @classmethod
    def prep(Daf,
             agg_id: Unsigned,
             agg_param: AggParam,
             nonce: bytes["Daf.NONCE_SIZE"],
             public_share: PublicShare,
             input_share: InputShare) -> OutShare:
        """
        Prepare an input share for aggregation. This algorithm takes in the
        public share and one of the input shares generated by the Client. It
        also takes the Aggregator's ID (a unique integer in range `[0, SHARES)`
        corresponding to the index of `input_share` in the Client's output),
        and an aggregation parameter and returns the corresponding output
        share.
        """
        raise NotImplementedError()

    @classmethod
    def aggregate(Daf,
                  agg_param: AggParam,
                  out_shares: list[OutShare]) -> AggShare:
        """
        Merge a list of output shares into an aggregate share, encoded as a byte
        string. This is called by an Aggregator after recovering a batch of
        output shares.
        """
        raise NotImplementedError()

    @classmethod
    def unshard(Daf,
                agg_param: AggParam,
                agg_shares: list[AggShare],
                num_measurements: Unsigned) -> AggResult:
        """
        Unshard the aggregate shares (encoded as byte strings) and compute the
        aggregate result. This is called by the Collector.
        """
        raise NotImplementedError()


def run_daf(Daf,
            agg_param: Daf.AggParam,
            measurements: list[Daf.Measurement],
            nonces: list[bytes["Daf.NONCE_SIZE"]]):
    """Run a DAF on a list of measurements."""
    out_shares = [[] for j in range(Daf.SHARES)]
    for (measurement, nonce) in zip(measurements, nonces):
        # Each Client shards its measurement into input shares and
        # distributes them among the Aggregators.
        rand = gen_rand(Daf.RAND_SIZE)
        (public_share, input_shares) = \
            Daf.shard(measurement, nonce, rand)

        # Each Aggregator prepares its input share for aggregation.
        for j in range(Daf.SHARES):
            out_shares[j].append(
                Daf.prep(j, agg_param, nonce,
                         public_share, input_shares[j]))

    # Each Aggregator aggregates its output shares into an aggregate
    # share and sends it to the Collector.
    agg_shares = []
    for j in range(Daf.SHARES):
        agg_share_j = Daf.aggregate(agg_param,
                                    out_shares[j])
        agg_shares.append(agg_share_j)

    # Collector unshards the aggregate result.
    num_measurements = len(measurements)
    agg_result = Daf.unshard(agg_param, agg_shares,
                             num_measurements)
    return agg_result
